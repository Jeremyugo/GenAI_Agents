{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe72fb2b",
   "metadata": {},
   "source": [
    "## RAG Evaluation\n",
    "\n",
    "using Synthetic Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "sys.path.append('..')\n",
    "from utils.config import ENV_FILE_PATH\n",
    "load_dotenv(ENV_FILE_PATH)\n",
    "\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "\n",
    "llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-nano\"))\n",
    "embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())\n",
    "\n",
    "path = './data/'\n",
    "loader = DirectoryLoader(path, glob=\"*.pdf\", loader_cls=PyMuPDFLoader)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e8386bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello Jerry! How can I assist you today?'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.graph import build_agent\n",
    "from uuid import uuid4\n",
    "\n",
    "query = \"Hi my name is Jerry\"\n",
    "config = {'configurable': {'thread_id': str(uuid4())}}\n",
    "\n",
    "rag_agent = build_agent()\n",
    "response = await rag_agent.ainvoke(\n",
    "    {\n",
    "        'messages': query\n",
    "    },\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 5, relationships: 0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.testset.graph import KnowledgeGraph\n",
    "from ragas.testset.graph import Node, NodeType\n",
    "\n",
    "kg = KnowledgeGraph()\n",
    "\n",
    "for doc in docs:\n",
    "    kg.nodes.append(\n",
    "        Node(\n",
    "            type=NodeType.DOCUMENT,\n",
    "            properties={\n",
    "                'page_content': doc.page_content,\n",
    "                'document_metadata': doc.metadata\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    \n",
    "kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc07acf3775948cd93db159a6a174777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying SummaryExtractor:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6b830dad9cd40528db7d3a9f0de67ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying CustomNodeFilter:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b94fb2b23d3946b583d83406c856f821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdcaa78fd906413d8f22ea3e407cdbd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 5, relationships: 15)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.testset.transforms import default_transforms, apply_transforms\n",
    "\n",
    "default_transforms = default_transforms(documents=docs, llm=llm, embedding_model=embeddings)\n",
    "apply_transforms(kg, default_transforms)\n",
    "kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 5, relationships: 15)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the knowledge graph to a json file\n",
    "\n",
    "kg.save('apple_intelligence_bloomberg_report.json')\n",
    "bloomberg_report = KnowledgeGraph.load('apple_intelligence_bloomberg_report.json')\n",
    "bloomberg_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "generator = TestsetGenerator(\n",
    "    llm=llm,\n",
    "    embedding_model=embeddings,\n",
    "    knowledge_graph=bloomberg_report\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.synthesizers import SingleHopSpecificQuerySynthesizer, MultiHopAbstractQuerySynthesizer, MultiHopSpecificQuerySynthesizer\n",
    "\n",
    "query_distribution = [\n",
    "        (SingleHopSpecificQuerySynthesizer(llm=llm), 0.5),\n",
    "        (MultiHopAbstractQuerySynthesizer(llm=llm), 0.25),\n",
    "        (MultiHopSpecificQuerySynthesizer(llm=llm), 0.25),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9405eaaa123f45408be7515ad3d07b69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating personas:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad379b230f024f7d93717f7f7d408517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3d3e14edd5645d8b951568a6487271f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Samples:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testset = generator.generate(\n",
    "    testset_size=10,\n",
    "    query_distribution=query_distribution\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Whaat is the date of March 14, 2025 in the con...</td>\n",
       "      <td>[Apple's AI Stumble:\\nIntelligence Delays and\\...</td>\n",
       "      <td>The date March 14, 2025, is mentioned as the p...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who is Tim Cook in the context of Apple's AI d...</td>\n",
       "      <td>[Memory constraints: Insufficient RAM on older...</td>\n",
       "      <td>Tim Cook is mentioned in the context of Apple'...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So, like, how does AI stuff, you know, impact ...</td>\n",
       "      <td>[Integration challenges: Difficulty incorporat...</td>\n",
       "      <td>Integration challenges include difficulty inco...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How is Apple's enterprise AI deployment compar...</td>\n",
       "      <td>[Enterprise AI Adoption\\nApple lags significan...</td>\n",
       "      <td>Apple lags significantly in enterprise AI depl...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How Apple AI Strategy plans to improve Enterpr...</td>\n",
       "      <td>[Services revenue: App Store and Apple Service...</td>\n",
       "      <td>Services revenue from the App Store and Apple ...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How do memory constraints on older devices imp...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nServices revenue: App Store and Ap...</td>\n",
       "      <td>Memory constraints on older devices limit the ...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>How do the technical constraints of on-device ...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nIntegration challenges: Difficulty...</td>\n",
       "      <td>The technical constraints of on-device AI proc...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>So, with all the integration challenges and te...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nIntegration challenges: Difficulty...</td>\n",
       "      <td>Apple faces significant integration challenges...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How do the integration challenges and talent r...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nIntegration challenges: Difficulty...</td>\n",
       "      <td>Apple faces integration challenges such as inc...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How does Google's involvement in AI acquisitio...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nApple's AI Stumble:\\nIntelligence ...</td>\n",
       "      <td>The context indicates that Apple has faced sig...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>How does Apple's AI challenge relate to the ne...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nMemory constraints: Insufficient R...</td>\n",
       "      <td>Apple's AI challenges, including memory constr...</td>\n",
       "      <td>multi_hop_specific_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_input  \\\n",
       "0   Whaat is the date of March 14, 2025 in the con...   \n",
       "1   Who is Tim Cook in the context of Apple's AI d...   \n",
       "2   So, like, how does AI stuff, you know, impact ...   \n",
       "3   How is Apple's enterprise AI deployment compar...   \n",
       "4   How Apple AI Strategy plans to improve Enterpr...   \n",
       "5   How do memory constraints on older devices imp...   \n",
       "6   How do the technical constraints of on-device ...   \n",
       "7   So, with all the integration challenges and te...   \n",
       "8   How do the integration challenges and talent r...   \n",
       "9   How does Google's involvement in AI acquisitio...   \n",
       "10  How does Apple's AI challenge relate to the ne...   \n",
       "\n",
       "                                   reference_contexts  \\\n",
       "0   [Apple's AI Stumble:\\nIntelligence Delays and\\...   \n",
       "1   [Memory constraints: Insufficient RAM on older...   \n",
       "2   [Integration challenges: Difficulty incorporat...   \n",
       "3   [Enterprise AI Adoption\\nApple lags significan...   \n",
       "4   [Services revenue: App Store and Apple Service...   \n",
       "5   [<1-hop>\\n\\nServices revenue: App Store and Ap...   \n",
       "6   [<1-hop>\\n\\nIntegration challenges: Difficulty...   \n",
       "7   [<1-hop>\\n\\nIntegration challenges: Difficulty...   \n",
       "8   [<1-hop>\\n\\nIntegration challenges: Difficulty...   \n",
       "9   [<1-hop>\\n\\nApple's AI Stumble:\\nIntelligence ...   \n",
       "10  [<1-hop>\\n\\nMemory constraints: Insufficient R...   \n",
       "\n",
       "                                            reference  \\\n",
       "0   The date March 14, 2025, is mentioned as the p...   \n",
       "1   Tim Cook is mentioned in the context of Apple'...   \n",
       "2   Integration challenges include difficulty inco...   \n",
       "3   Apple lags significantly in enterprise AI depl...   \n",
       "4   Services revenue from the App Store and Apple ...   \n",
       "5   Memory constraints on older devices limit the ...   \n",
       "6   The technical constraints of on-device AI proc...   \n",
       "7   Apple faces significant integration challenges...   \n",
       "8   Apple faces integration challenges such as inc...   \n",
       "9   The context indicates that Apple has faced sig...   \n",
       "10  Apple's AI challenges, including memory constr...   \n",
       "\n",
       "                        synthesizer_name  \n",
       "0   single_hop_specifc_query_synthesizer  \n",
       "1   single_hop_specifc_query_synthesizer  \n",
       "2   single_hop_specifc_query_synthesizer  \n",
       "3   single_hop_specifc_query_synthesizer  \n",
       "4   single_hop_specifc_query_synthesizer  \n",
       "5   multi_hop_abstract_query_synthesizer  \n",
       "6   multi_hop_abstract_query_synthesizer  \n",
       "7   multi_hop_abstract_query_synthesizer  \n",
       "8   multi_hop_specific_query_synthesizer  \n",
       "9   multi_hop_specific_query_synthesizer  \n",
       "10  multi_hop_specific_query_synthesizer  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset_df = testset.to_pandas()\n",
    "testset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfa5a23",
   "metadata": {},
   "source": [
    "### LangSmith Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "\n",
    "dataset_name = 'Apple Intelligence Bloomberg Report'\n",
    "\n",
    "langsmith_dataset = client.create_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    description=\"Bloomberg Report on the state of Apple's Intelligence\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26c54380",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_row in testset_df.itertuples():\n",
    "    client.create_example(\n",
    "        inputs={\n",
    "            'messages': data_row.user_input\n",
    "        },\n",
    "        outputs={\n",
    "            'answer': data_row.reference\n",
    "        },\n",
    "        metadata={\n",
    "            'context': data_row.reference_contexts\n",
    "        },\n",
    "        dataset_id=langsmith_dataset.id\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.evaluation import LangChainStringEvaluator, aevaluate\n",
    "\n",
    "eval_llm = ChatOpenAI(model='gpt-4.1')\n",
    "\n",
    "qa_evaluator = LangChainStringEvaluator(\"qa\", config={\"llm\" : eval_llm})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f213d08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def eval_wrapper(inputs: dict):\n",
    "    \"\"\"\n",
    "    Take dataset inputs (which have {\"messages\": ...})\n",
    "    and feed them to your rag_agent properly.\n",
    "    \"\"\"\n",
    "    response = await rag_agent.ainvoke({\"messages\": inputs[\"messages\"]})\n",
    "    \n",
    "    output = response['messages'][-1].content\n",
    "    \n",
    "    return {\n",
    "        'output': output\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'stupendous-child-61' at:\n",
      "https://smith.langchain.com/o/82f2f79c-f7d4-4fda-a89e-d181cfe5bf92/datasets/ecc8d5cf-2e7e-425b-a483-4a625658e7ce/compare?selectedSessions=e7ece4be-86c1-45c1-b235-3b1fe8758cd1\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f34c770cd8f5451cb85aaa236a496ce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/datascience/Generative-AI-Agents-langChain-langGraph-/self-corrective-agentic-RAG/src/vector.py:114: LangChainDeprecationWarning: The class `Qdrant` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-qdrant package and should be used instead. To use it run `pip install -U :class:`~langchain-qdrant` and import as `from :class:`~langchain_qdrant import Qdrant``.\n",
      "  vectorstore = Qdrant(\n",
      "\u001b[32m2025-08-24 19:18:51.673\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.knowledge_graph\u001b[0m:\u001b[36msearch_knowledge_graph\u001b[0m:\u001b[36m67\u001b[0m - \u001b[1mSearching knowledge graph...\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://ec63adcb-fe29-4b49-9d9c-311e1e7c903b.us-east4-0.gcp.cloud.qdrant.io:6333/collections/self_corrective_agentic_rag/points/search \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL DOCUMENTS ARE NOT RELEVANT TO THE QUESTION, TRANSFORM QUERY...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-08-24 19:19:07.220\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.knowledge_graph\u001b[0m:\u001b[36msearch_knowledge_graph\u001b[0m:\u001b[36m67\u001b[0m - \u001b[1mSearching knowledge graph...\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://ec63adcb-fe29-4b49-9d9c-311e1e7c903b.us-east4-0.gcp.cloud.qdrant.io:6333/collections/self_corrective_agentic_rag/points/search \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL DOCUMENTS ARE NOT RELEVANT TO THE QUESTION, TRANSFORM QUERY...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-08-24 19:19:22.544\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.knowledge_graph\u001b[0m:\u001b[36msearch_knowledge_graph\u001b[0m:\u001b[36m67\u001b[0m - \u001b[1mSearching knowledge graph...\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://ec63adcb-fe29-4b49-9d9c-311e1e7c903b.us-east4-0.gcp.cloud.qdrant.io:6333/collections/self_corrective_agentic_rag/points/search \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL DOCUMENTS ARE NOT RELEVANT TO THE QUESTION, TRANSFORM QUERY...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-08-24 19:19:36.943\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.knowledge_graph\u001b[0m:\u001b[36msearch_knowledge_graph\u001b[0m:\u001b[36m67\u001b[0m - \u001b[1mSearching knowledge graph...\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://ec63adcb-fe29-4b49-9d9c-311e1e7c903b.us-east4-0.gcp.cloud.qdrant.io:6333/collections/self_corrective_agentic_rag/points/search \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL DOCUMENTS ARE NOT RELEVANT TO THE QUESTION, TRANSFORM QUERY...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-08-24 19:19:50.692\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.knowledge_graph\u001b[0m:\u001b[36msearch_knowledge_graph\u001b[0m:\u001b[36m67\u001b[0m - \u001b[1mSearching knowledge graph...\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://ec63adcb-fe29-4b49-9d9c-311e1e7c903b.us-east4-0.gcp.cloud.qdrant.io:6333/collections/self_corrective_agentic_rag/points/search \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL DOCUMENTS ARE NOT RELEVANT TO THE QUESTION, TRANSFORM QUERY...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-08-24 19:20:04.986\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.knowledge_graph\u001b[0m:\u001b[36msearch_knowledge_graph\u001b[0m:\u001b[36m67\u001b[0m - \u001b[1mSearching knowledge graph...\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://ec63adcb-fe29-4b49-9d9c-311e1e7c903b.us-east4-0.gcp.cloud.qdrant.io:6333/collections/self_corrective_agentic_rag/points/search \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL DOCUMENTS ARE NOT RELEVANT TO THE QUESTION, TRANSFORM QUERY...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-08-24 19:20:18.375\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.knowledge_graph\u001b[0m:\u001b[36msearch_knowledge_graph\u001b[0m:\u001b[36m67\u001b[0m - \u001b[1mSearching knowledge graph...\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://ec63adcb-fe29-4b49-9d9c-311e1e7c903b.us-east4-0.gcp.cloud.qdrant.io:6333/collections/self_corrective_agentic_rag/points/search \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL DOCUMENTS ARE NOT RELEVANT TO THE QUESTION, TRANSFORM QUERY...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-08-24 19:20:34.147\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.knowledge_graph\u001b[0m:\u001b[36msearch_knowledge_graph\u001b[0m:\u001b[36m67\u001b[0m - \u001b[1mSearching knowledge graph...\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://ec63adcb-fe29-4b49-9d9c-311e1e7c903b.us-east4-0.gcp.cloud.qdrant.io:6333/collections/self_corrective_agentic_rag/points/search \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL DOCUMENTS ARE NOT RELEVANT TO THE QUESTION, TRANSFORM QUERY...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-08-24 19:20:49.674\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.knowledge_graph\u001b[0m:\u001b[36msearch_knowledge_graph\u001b[0m:\u001b[36m67\u001b[0m - \u001b[1mSearching knowledge graph...\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://ec63adcb-fe29-4b49-9d9c-311e1e7c903b.us-east4-0.gcp.cloud.qdrant.io:6333/collections/self_corrective_agentic_rag/points/search \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENERATE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-08-24 19:21:01.521\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.knowledge_graph\u001b[0m:\u001b[36msearch_knowledge_graph\u001b[0m:\u001b[36m67\u001b[0m - \u001b[1mSearching knowledge graph...\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://ec63adcb-fe29-4b49-9d9c-311e1e7c903b.us-east4-0.gcp.cloud.qdrant.io:6333/collections/self_corrective_agentic_rag/points/search \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL DOCUMENTS ARE NOT RELEVANT TO THE QUESTION, TRANSFORM QUERY...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[32m2025-08-24 19:21:15.989\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.knowledge_graph\u001b[0m:\u001b[36msearch_knowledge_graph\u001b[0m:\u001b[36m67\u001b[0m - \u001b[1mSearching knowledge graph...\u001b[0m\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://ec63adcb-fe29-4b49-9d9c-311e1e7c903b.us-east4-0.gcp.cloud.qdrant.io:6333/collections/self_corrective_agentic_rag/points/search \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL DOCUMENTS ARE NOT RELEVANT TO THE QUESTION, TRANSFORM QUERY...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "eval_result = await aevaluate(\n",
    "    eval_wrapper,\n",
    "    data=dataset_name,\n",
    "    evaluators=[\n",
    "        qa_evaluator,\n",
    "    ],\n",
    "    metadata={\"revision_id\": \"default_chain_init\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cab2a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c58f40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
